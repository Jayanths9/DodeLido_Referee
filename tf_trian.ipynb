{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jayanths9/Dodelido_opencv/blob/main/Jay_Single_Image_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8RDuGXyYGVi",
        "outputId": "dc3545be-3404-414e-b5c9-f61942004a8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2l8hbH30cFe"
      },
      "outputs": [],
      "source": [
        "# Importing Library Files\n",
        "import albumentations as A\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import json\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_V5hYh-YEeL"
      },
      "outputs": [],
      "source": [
        "dir_path='/content/drive/MyDrive/dodelido/'\n",
        "image_dir=\"/content/drive/MyDrive/dodelido/dataset/\"\n",
        "data = pd.read_json(f\"{dir_path}/labels.json\").T\n",
        "data = data.sort_index(ascending=True)\n",
        "data = data.reset_index()\n",
        "\n",
        "data[\"animal_color\"] = data.apply(lambda row: [row[0], row[1]], axis=1)\n",
        "data['labels'] = list(zip(data[0], data[1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iaraqYZbqJf",
        "outputId": "1160b612-3c4a-4a6d-8a76-35f7a8d90d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of posters for training:  1712\n",
            "Number of posters for validation:  428\n"
          ]
        }
      ],
      "source": [
        "# Splitting the dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    data['index'], data['animal_color'], test_size=0.2, random_state=44)\n",
        "\n",
        "print(\"Number of posters for training: \", len(X_train))\n",
        "print(\"Number of posters for validation: \", len(X_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht_8kbnKrtXT",
        "outputId": "c66dfd14-23b5-4598-ff08-7cdf8777b755"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['snake', 'blue'], ['lion', 'green'], ['lion', 'blue'], ['giraffe', 'green']]\n",
            "0. alarm\n",
            "1. blue\n",
            "2. crane\n",
            "3. giraffe\n",
            "4. green\n",
            "5. grey\n",
            "6. lion\n",
            "7. monkey\n",
            "8. pink\n",
            "9. sloth\n",
            "10. snake\n",
            "11. yellow\n"
          ]
        }
      ],
      "source": [
        "# The targets should be a list of list of strings to fit a binarizer (multi-hot encoding).\n",
        "\n",
        "y_train = list(y_train)\n",
        "y_val = list(y_val)\n",
        "\n",
        "print(y_val[:4])\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Fit the multi-label binarizer on the training set\n",
        "mlb = MultiLabelBinarizer()\n",
        "mlb.fit(y_train)\n",
        "\n",
        "# Loop over all labels and show them\n",
        "N_LABELS = len(mlb.classes_)\n",
        "for (i, label) in enumerate(mlb.classes_):\n",
        "    print(\"{}. {}\".format(i, label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlaHYnkX4hAT",
        "outputId": "7334135b-97d9-4de1-edf8-82aff48bb6b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.png [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "0_180.png [0 0 0 0 0 1 0 0 0 0 1 0]\n",
            "0_270.png [0 1 0 0 0 0 0 0 0 0 1 0]\n"
          ]
        }
      ],
      "source": [
        "# transform the targets of the training and test sets\n",
        "y_train_bin = mlb.transform(y_train)\n",
        "y_val_bin = mlb.transform(y_val)\n",
        "\n",
        "# Print example of images and their binary targets\n",
        "for i in range(3):\n",
        "    print(X_train[i], y_train_bin[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06lASCBHPnRQ"
      },
      "source": [
        "Workflow:\n",
        "\n",
        "1.   Data collection\n",
        "2.   Data preparation\n",
        "3.   Create a fast input pipeline in TensorFlow\n",
        "4.   Build up the model\n",
        "5.   Get a transfer learning layer using TensorFlow Hub\n",
        "6.   Stack a multi-label neural network classifier on top\n",
        "7.   Model training and evaluation\n",
        "8.   Understand the role of macro soft-F1 loss\n",
        "9.   Export and save tf.keras models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8rE5G7HPICr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = 224 # Specify height and width of image to match the input format of the model\n",
        "CHANNELS = 3 # Keep RGB color channels to match the input format of the model\n",
        "BATCH_SIZE = 256 # Big enough to measure an F1-score\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
        "SHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations\n",
        "\n",
        "def parse_function(filename, label):\n",
        "    \"\"\"Function that returns a tuple of normalized image array and labels array.\n",
        "    Args:\n",
        "        filename: string representing path to image\n",
        "        label: 0/1 one-dimensional array of size N_LABELS\n",
        "    \"\"\"\n",
        "    # filename=image_dir+filename\n",
        "    # Read an image from a file\n",
        "    image_string = tf.io.read_file(filename)\n",
        "    # Decode it into a dense vector\n",
        "    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
        "    # Resize it to fixed shape\n",
        "    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n",
        "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
        "    image_normalized = image_resized / 255.0\n",
        "    return image_normalized, label\n",
        "\n",
        "\n",
        "def create_dataset(filenames, labels, is_training=True):\n",
        "    \"\"\"Load and parse dataset.\n",
        "    Args:\n",
        "        filenames: list of image paths\n",
        "        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n",
        "        is_training: boolean to indicate training mode\n",
        "    \"\"\"\n",
        "    filenames=image_dir+filenames\n",
        "\n",
        "    # Create a first dataset of file paths and labels\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
        "    # Parse and preprocess observations in parallel\n",
        "    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    if is_training == True:\n",
        "        # This is a small dataset, only load it once, and keep it in memory.\n",
        "        dataset = dataset.cache()\n",
        "        # Shuffle the data each buffer size\n",
        "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
        "\n",
        "    # Batch the data for multiple steps\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    # Fetch batches in the background while the model is training.\n",
        "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUg3bF4kvPhE",
        "outputId": "51417d1c-d8b8-4d80-ba08-967292caeb4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "428"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_val_bin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRysljQuRE1-"
      },
      "outputs": [],
      "source": [
        "train_ds1 = create_dataset(X_train, y_train_bin)\n",
        "val_ds1 = create_dataset(X_val, y_val_bin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcNo0XR2RVn8"
      },
      "source": [
        "\n",
        "\n",
        "Each batch will be a pair of arrays (one that holds the features and another one that holds the labels).\n",
        "The features array will be of shape (BATCH_SIZE, IMG_SIZE, IMG_SIZE, CHANNELS).\n",
        "The labels array will be of shape (BATCH_SIZE, N_LABELS) where N_LABELS is the maximum number of labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGaCiGaQRghv"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "from keras import layers\n",
        "\n",
        "feature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
        "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
        "                                         input_shape=(IMG_SIZE,IMG_SIZE,CHANNELS))\n",
        "feature_extractor_layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgUZaNnWTp-l",
        "outputId": "9d7a5728-2418-451b-904a-ffef428d954f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
            "                                                                 \n",
            " hidden_layer (Dense)        (None, 1024)              1311744   \n",
            "                                                                 \n",
            " output (Dense)              (None, 12)                12300     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3582028 (13.66 MB)\n",
            "Trainable params: 1324044 (5.05 MB)\n",
            "Non-trainable params: 2257984 (8.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [feature_extractor_layer,\n",
        "    layers.Dense(1024, activation='relu', name='hidden_layer'),\n",
        "    layers.Dense(N_LABELS, activation='sigmoid', name='output')])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF6ZitpKEXL5"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def macro_soft_f1(y, y_hat):\n",
        "    \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n",
        "    Use probability values instead of binary predictions.\n",
        "\n",
        "    Args:\n",
        "        y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n",
        "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
        "\n",
        "    Returns:\n",
        "        cost (scalar Tensor): value of the cost function for the batch\n",
        "    \"\"\"\n",
        "    y = tf.cast(y, tf.float32)\n",
        "    y_hat = tf.cast(y_hat, tf.float32)\n",
        "    tp = tf.reduce_sum(y_hat * y, axis=0)\n",
        "    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n",
        "    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n",
        "    soft_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
        "    cost = 1 - soft_f1 # reduce 1 - soft-f1 in order to increase soft-f1\n",
        "    macro_cost = tf.reduce_mean(cost) # average on all labels\n",
        "    return macro_cost\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def macro_f1(y, y_hat, thresh=0.5):\n",
        "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
        "\n",
        "    Args:\n",
        "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
        "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
        "        thresh: probability value above which we predict positive\n",
        "\n",
        "    Returns:\n",
        "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
        "    \"\"\"\n",
        "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
        "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
        "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
        "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
        "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
        "    macro_f1 = tf.reduce_mean(f1)\n",
        "    return macro_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z79DO-MqEq__",
        "outputId": "e81dc397-d486-4832-b555-0867506ae3b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "7/7 [==============================] - 8s 808ms/step - loss: 0.1011 - macro_f1: 0.9836 - val_loss: 0.0989 - val_macro_f1: 0.9806\n",
            "Epoch 2/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0832 - macro_f1: 0.9877 - val_loss: 0.0856 - val_macro_f1: 0.9795\n",
            "Epoch 3/200\n",
            "7/7 [==============================] - 5s 712ms/step - loss: 0.0698 - macro_f1: 0.9900 - val_loss: 0.0726 - val_macro_f1: 0.9825\n",
            "Epoch 4/200\n",
            "7/7 [==============================] - 5s 698ms/step - loss: 0.0594 - macro_f1: 0.9908 - val_loss: 0.0645 - val_macro_f1: 0.9834\n",
            "Epoch 5/200\n",
            "7/7 [==============================] - 5s 718ms/step - loss: 0.0509 - macro_f1: 0.9924 - val_loss: 0.0554 - val_macro_f1: 0.9868\n",
            "Epoch 6/200\n",
            "7/7 [==============================] - 5s 709ms/step - loss: 0.0434 - macro_f1: 0.9940 - val_loss: 0.0496 - val_macro_f1: 0.9879\n",
            "Epoch 7/200\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.0376 - macro_f1: 0.9950 - val_loss: 0.0441 - val_macro_f1: 0.9891\n",
            "Epoch 8/200\n",
            "7/7 [==============================] - 5s 719ms/step - loss: 0.0332 - macro_f1: 0.9955 - val_loss: 0.0397 - val_macro_f1: 0.9909\n",
            "Epoch 9/200\n",
            "7/7 [==============================] - 4s 662ms/step - loss: 0.0297 - macro_f1: 0.9952 - val_loss: 0.0362 - val_macro_f1: 0.9917\n",
            "Epoch 10/200\n",
            "7/7 [==============================] - 5s 746ms/step - loss: 0.0263 - macro_f1: 0.9963 - val_loss: 0.0329 - val_macro_f1: 0.9917\n",
            "Epoch 11/200\n",
            "7/7 [==============================] - 4s 610ms/step - loss: 0.0239 - macro_f1: 0.9965 - val_loss: 0.0305 - val_macro_f1: 0.9917\n",
            "Epoch 12/200\n",
            "7/7 [==============================] - 6s 844ms/step - loss: 0.0218 - macro_f1: 0.9966 - val_loss: 0.0283 - val_macro_f1: 0.9933\n",
            "Epoch 13/200\n",
            "7/7 [==============================] - 5s 723ms/step - loss: 0.0199 - macro_f1: 0.9968 - val_loss: 0.0261 - val_macro_f1: 0.9933\n",
            "Epoch 14/200\n",
            "7/7 [==============================] - 5s 756ms/step - loss: 0.0182 - macro_f1: 0.9968 - val_loss: 0.0245 - val_macro_f1: 0.9938\n",
            "Epoch 15/200\n",
            "7/7 [==============================] - 5s 722ms/step - loss: 0.0167 - macro_f1: 0.9977 - val_loss: 0.0233 - val_macro_f1: 0.9938\n",
            "Epoch 16/200\n",
            "7/7 [==============================] - 5s 689ms/step - loss: 0.0155 - macro_f1: 0.9975 - val_loss: 0.0215 - val_macro_f1: 0.9938\n",
            "Epoch 17/200\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.0144 - macro_f1: 0.9974 - val_loss: 0.0204 - val_macro_f1: 0.9938\n",
            "Epoch 18/200\n",
            "7/7 [==============================] - 4s 576ms/step - loss: 0.0132 - macro_f1: 0.9978 - val_loss: 0.0194 - val_macro_f1: 0.9938\n",
            "Epoch 19/200\n",
            "7/7 [==============================] - 5s 706ms/step - loss: 0.0124 - macro_f1: 0.9979 - val_loss: 0.0184 - val_macro_f1: 0.9945\n",
            "Epoch 20/200\n",
            "7/7 [==============================] - 4s 591ms/step - loss: 0.0116 - macro_f1: 0.9984 - val_loss: 0.0177 - val_macro_f1: 0.9945\n",
            "Epoch 21/200\n",
            "7/7 [==============================] - 4s 580ms/step - loss: 0.0111 - macro_f1: 0.9983 - val_loss: 0.0169 - val_macro_f1: 0.9951\n",
            "Epoch 22/200\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.0103 - macro_f1: 0.9986 - val_loss: 0.0161 - val_macro_f1: 0.9951\n",
            "Epoch 23/200\n",
            "7/7 [==============================] - 5s 717ms/step - loss: 0.0097 - macro_f1: 0.9987 - val_loss: 0.0155 - val_macro_f1: 0.9951\n",
            "Epoch 24/200\n",
            "7/7 [==============================] - 4s 550ms/step - loss: 0.0092 - macro_f1: 0.9985 - val_loss: 0.0149 - val_macro_f1: 0.9951\n",
            "Epoch 25/200\n",
            "7/7 [==============================] - 5s 722ms/step - loss: 0.0087 - macro_f1: 0.9985 - val_loss: 0.0144 - val_macro_f1: 0.9951\n",
            "Epoch 26/200\n",
            "7/7 [==============================] - 5s 709ms/step - loss: 0.0083 - macro_f1: 0.9984 - val_loss: 0.0140 - val_macro_f1: 0.9951\n",
            "Epoch 27/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0078 - macro_f1: 0.9986 - val_loss: 0.0135 - val_macro_f1: 0.9951\n",
            "Epoch 28/200\n",
            "7/7 [==============================] - 4s 562ms/step - loss: 0.0073 - macro_f1: 0.9987 - val_loss: 0.0130 - val_macro_f1: 0.9951\n",
            "Epoch 29/200\n",
            "7/7 [==============================] - 5s 728ms/step - loss: 0.0070 - macro_f1: 0.9988 - val_loss: 0.0127 - val_macro_f1: 0.9951\n",
            "Epoch 30/200\n",
            "7/7 [==============================] - 5s 755ms/step - loss: 0.0068 - macro_f1: 0.9988 - val_loss: 0.0124 - val_macro_f1: 0.9951\n",
            "Epoch 31/200\n",
            "7/7 [==============================] - 5s 721ms/step - loss: 0.0063 - macro_f1: 0.9989 - val_loss: 0.0120 - val_macro_f1: 0.9951\n",
            "Epoch 32/200\n",
            "7/7 [==============================] - 5s 722ms/step - loss: 0.0061 - macro_f1: 0.9989 - val_loss: 0.0116 - val_macro_f1: 0.9951\n",
            "Epoch 33/200\n",
            "7/7 [==============================] - 6s 855ms/step - loss: 0.0060 - macro_f1: 0.9989 - val_loss: 0.0115 - val_macro_f1: 0.9951\n",
            "Epoch 34/200\n",
            "7/7 [==============================] - 5s 786ms/step - loss: 0.0056 - macro_f1: 0.9990 - val_loss: 0.0111 - val_macro_f1: 0.9951\n",
            "Epoch 35/200\n",
            "7/7 [==============================] - 4s 564ms/step - loss: 0.0054 - macro_f1: 0.9990 - val_loss: 0.0109 - val_macro_f1: 0.9951\n",
            "Epoch 36/200\n",
            "7/7 [==============================] - 4s 583ms/step - loss: 0.0052 - macro_f1: 0.9990 - val_loss: 0.0106 - val_macro_f1: 0.9951\n",
            "Epoch 37/200\n",
            "7/7 [==============================] - 5s 792ms/step - loss: 0.0051 - macro_f1: 0.9990 - val_loss: 0.0104 - val_macro_f1: 0.9951\n",
            "Epoch 38/200\n",
            "7/7 [==============================] - 4s 561ms/step - loss: 0.0049 - macro_f1: 0.9988 - val_loss: 0.0102 - val_macro_f1: 0.9951\n",
            "Epoch 39/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0047 - macro_f1: 0.9990 - val_loss: 0.0100 - val_macro_f1: 0.9951\n",
            "Epoch 40/200\n",
            "7/7 [==============================] - 4s 585ms/step - loss: 0.0045 - macro_f1: 0.9990 - val_loss: 0.0097 - val_macro_f1: 0.9951\n",
            "Epoch 41/200\n",
            "7/7 [==============================] - 4s 558ms/step - loss: 0.0043 - macro_f1: 0.9990 - val_loss: 0.0096 - val_macro_f1: 0.9951\n",
            "Epoch 42/200\n",
            "7/7 [==============================] - 4s 618ms/step - loss: 0.0043 - macro_f1: 0.9989 - val_loss: 0.0095 - val_macro_f1: 0.9951\n",
            "Epoch 43/200\n",
            "7/7 [==============================] - 5s 750ms/step - loss: 0.0041 - macro_f1: 0.9988 - val_loss: 0.0093 - val_macro_f1: 0.9951\n",
            "Epoch 44/200\n",
            "7/7 [==============================] - 5s 720ms/step - loss: 0.0040 - macro_f1: 0.9989 - val_loss: 0.0091 - val_macro_f1: 0.9951\n",
            "Epoch 45/200\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.0039 - macro_f1: 0.9988 - val_loss: 0.0090 - val_macro_f1: 0.9951\n",
            "Epoch 46/200\n",
            "7/7 [==============================] - 4s 569ms/step - loss: 0.0038 - macro_f1: 0.9991 - val_loss: 0.0089 - val_macro_f1: 0.9951\n",
            "Epoch 47/200\n",
            "7/7 [==============================] - 4s 558ms/step - loss: 0.0035 - macro_f1: 0.9991 - val_loss: 0.0087 - val_macro_f1: 0.9951\n",
            "Epoch 48/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0035 - macro_f1: 0.9992 - val_loss: 0.0086 - val_macro_f1: 0.9951\n",
            "Epoch 49/200\n",
            "7/7 [==============================] - 5s 755ms/step - loss: 0.0034 - macro_f1: 0.9990 - val_loss: 0.0085 - val_macro_f1: 0.9951\n",
            "Epoch 50/200\n",
            "7/7 [==============================] - 5s 697ms/step - loss: 0.0034 - macro_f1: 0.9993 - val_loss: 0.0085 - val_macro_f1: 0.9951\n",
            "Epoch 51/200\n",
            "7/7 [==============================] - 5s 704ms/step - loss: 0.0031 - macro_f1: 0.9994 - val_loss: 0.0083 - val_macro_f1: 0.9951\n",
            "Epoch 52/200\n",
            "7/7 [==============================] - 4s 582ms/step - loss: 0.0031 - macro_f1: 0.9993 - val_loss: 0.0083 - val_macro_f1: 0.9951\n",
            "Epoch 53/200\n",
            "7/7 [==============================] - 5s 786ms/step - loss: 0.0031 - macro_f1: 0.9991 - val_loss: 0.0081 - val_macro_f1: 0.9951\n",
            "Epoch 54/200\n",
            "7/7 [==============================] - 4s 574ms/step - loss: 0.0029 - macro_f1: 0.9994 - val_loss: 0.0080 - val_macro_f1: 0.9951\n",
            "Epoch 55/200\n",
            "7/7 [==============================] - 5s 720ms/step - loss: 0.0028 - macro_f1: 0.9994 - val_loss: 0.0079 - val_macro_f1: 0.9951\n",
            "Epoch 56/200\n",
            "7/7 [==============================] - 5s 769ms/step - loss: 0.0027 - macro_f1: 0.9994 - val_loss: 0.0078 - val_macro_f1: 0.9951\n",
            "Epoch 57/200\n",
            "7/7 [==============================] - 4s 574ms/step - loss: 0.0027 - macro_f1: 0.9992 - val_loss: 0.0077 - val_macro_f1: 0.9951\n",
            "Epoch 58/200\n",
            "7/7 [==============================] - 5s 715ms/step - loss: 0.0026 - macro_f1: 0.9994 - val_loss: 0.0077 - val_macro_f1: 0.9951\n",
            "Epoch 59/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0027 - macro_f1: 0.9993 - val_loss: 0.0075 - val_macro_f1: 0.9951\n",
            "Epoch 60/200\n",
            "7/7 [==============================] - 5s 742ms/step - loss: 0.0025 - macro_f1: 0.9993 - val_loss: 0.0075 - val_macro_f1: 0.9951\n",
            "Epoch 61/200\n",
            "7/7 [==============================] - 5s 697ms/step - loss: 0.0024 - macro_f1: 0.9992 - val_loss: 0.0074 - val_macro_f1: 0.9951\n",
            "Epoch 62/200\n",
            "7/7 [==============================] - 4s 600ms/step - loss: 0.0024 - macro_f1: 0.9994 - val_loss: 0.0073 - val_macro_f1: 0.9951\n",
            "Epoch 63/200\n",
            "7/7 [==============================] - 5s 713ms/step - loss: 0.0024 - macro_f1: 0.9992 - val_loss: 0.0073 - val_macro_f1: 0.9951\n",
            "Epoch 64/200\n",
            "7/7 [==============================] - 5s 725ms/step - loss: 0.0023 - macro_f1: 0.9993 - val_loss: 0.0073 - val_macro_f1: 0.9951\n",
            "Epoch 65/200\n",
            "7/7 [==============================] - 4s 577ms/step - loss: 0.0023 - macro_f1: 0.9993 - val_loss: 0.0072 - val_macro_f1: 0.9951\n",
            "Epoch 66/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0024 - macro_f1: 0.9992 - val_loss: 0.0071 - val_macro_f1: 0.9951\n",
            "Epoch 67/200\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.0022 - macro_f1: 0.9993 - val_loss: 0.0070 - val_macro_f1: 0.9951\n",
            "Epoch 68/200\n",
            "7/7 [==============================] - 5s 713ms/step - loss: 0.0021 - macro_f1: 0.9993 - val_loss: 0.0070 - val_macro_f1: 0.9951\n",
            "Epoch 69/200\n",
            "7/7 [==============================] - 4s 658ms/step - loss: 0.0022 - macro_f1: 0.9992 - val_loss: 0.0070 - val_macro_f1: 0.9951\n",
            "Epoch 70/200\n",
            "7/7 [==============================] - 4s 632ms/step - loss: 0.0021 - macro_f1: 0.9993 - val_loss: 0.0068 - val_macro_f1: 0.9951\n",
            "Epoch 71/200\n",
            "7/7 [==============================] - 5s 744ms/step - loss: 0.0019 - macro_f1: 0.9994 - val_loss: 0.0068 - val_macro_f1: 0.9951\n",
            "Epoch 72/200\n",
            "7/7 [==============================] - 4s 582ms/step - loss: 0.0020 - macro_f1: 0.9993 - val_loss: 0.0068 - val_macro_f1: 0.9951\n",
            "Epoch 73/200\n",
            "7/7 [==============================] - 5s 751ms/step - loss: 0.0019 - macro_f1: 0.9993 - val_loss: 0.0067 - val_macro_f1: 0.9951\n",
            "Epoch 74/200\n",
            "7/7 [==============================] - 5s 719ms/step - loss: 0.0020 - macro_f1: 0.9993 - val_loss: 0.0067 - val_macro_f1: 0.9951\n",
            "Epoch 75/200\n",
            "7/7 [==============================] - 4s 572ms/step - loss: 0.0018 - macro_f1: 0.9994 - val_loss: 0.0066 - val_macro_f1: 0.9951\n",
            "Epoch 76/200\n",
            "7/7 [==============================] - 5s 791ms/step - loss: 0.0019 - macro_f1: 0.9993 - val_loss: 0.0066 - val_macro_f1: 0.9951\n",
            "Epoch 77/200\n",
            "7/7 [==============================] - 4s 568ms/step - loss: 0.0018 - macro_f1: 0.9994 - val_loss: 0.0065 - val_macro_f1: 0.9951\n",
            "Epoch 78/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0018 - macro_f1: 0.9993 - val_loss: 0.0065 - val_macro_f1: 0.9951\n",
            "Epoch 79/200\n",
            "7/7 [==============================] - 5s 715ms/step - loss: 0.0017 - macro_f1: 0.9994 - val_loss: 0.0065 - val_macro_f1: 0.9951\n",
            "Epoch 80/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0017 - macro_f1: 0.9993 - val_loss: 0.0064 - val_macro_f1: 0.9951\n",
            "Epoch 81/200\n",
            "7/7 [==============================] - 5s 755ms/step - loss: 0.0018 - macro_f1: 0.9993 - val_loss: 0.0064 - val_macro_f1: 0.9951\n",
            "Epoch 82/200\n",
            "7/7 [==============================] - 5s 708ms/step - loss: 0.0017 - macro_f1: 0.9994 - val_loss: 0.0063 - val_macro_f1: 0.9951\n",
            "Epoch 83/200\n",
            "7/7 [==============================] - 4s 594ms/step - loss: 0.0017 - macro_f1: 0.9993 - val_loss: 0.0063 - val_macro_f1: 0.9951\n",
            "Epoch 84/200\n",
            "7/7 [==============================] - 5s 708ms/step - loss: 0.0017 - macro_f1: 0.9993 - val_loss: 0.0063 - val_macro_f1: 0.9951\n",
            "Epoch 85/200\n",
            "7/7 [==============================] - 4s 609ms/step - loss: 0.0016 - macro_f1: 0.9994 - val_loss: 0.0063 - val_macro_f1: 0.9951\n",
            "Epoch 86/200\n",
            "7/7 [==============================] - 5s 756ms/step - loss: 0.0016 - macro_f1: 0.9993 - val_loss: 0.0062 - val_macro_f1: 0.9951\n",
            "Epoch 87/200\n",
            "7/7 [==============================] - 5s 753ms/step - loss: 0.0016 - macro_f1: 0.9994 - val_loss: 0.0061 - val_macro_f1: 0.9951\n",
            "Epoch 88/200\n",
            "7/7 [==============================] - 4s 561ms/step - loss: 0.0016 - macro_f1: 0.9993 - val_loss: 0.0061 - val_macro_f1: 0.9951\n",
            "Epoch 89/200\n",
            "7/7 [==============================] - 5s 777ms/step - loss: 0.0015 - macro_f1: 0.9994 - val_loss: 0.0062 - val_macro_f1: 0.9951\n",
            "Epoch 90/200\n",
            "7/7 [==============================] - 4s 554ms/step - loss: 0.0016 - macro_f1: 0.9993 - val_loss: 0.0061 - val_macro_f1: 0.9951\n",
            "Epoch 91/200\n",
            "7/7 [==============================] - 5s 713ms/step - loss: 0.0015 - macro_f1: 0.9993 - val_loss: 0.0060 - val_macro_f1: 0.9951\n",
            "Epoch 92/200\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.0015 - macro_f1: 0.9994 - val_loss: 0.0060 - val_macro_f1: 0.9951\n",
            "Epoch 93/200\n",
            "7/7 [==============================] - 4s 582ms/step - loss: 0.0015 - macro_f1: 0.9993 - val_loss: 0.0060 - val_macro_f1: 0.9951\n",
            "Epoch 94/200\n",
            "7/7 [==============================] - 5s 757ms/step - loss: 0.0015 - macro_f1: 0.9993 - val_loss: 0.0060 - val_macro_f1: 0.9951\n",
            "Epoch 95/200\n",
            "7/7 [==============================] - 4s 578ms/step - loss: 0.0015 - macro_f1: 0.9993 - val_loss: 0.0060 - val_macro_f1: 0.9951\n",
            "Epoch 96/200\n",
            "7/7 [==============================] - 4s 661ms/step - loss: 0.0015 - macro_f1: 0.9993 - val_loss: 0.0059 - val_macro_f1: 0.9951\n",
            "Epoch 97/200\n",
            "7/7 [==============================] - 5s 762ms/step - loss: 0.0014 - macro_f1: 0.9993 - val_loss: 0.0059 - val_macro_f1: 0.9951\n",
            "Epoch 98/200\n",
            "7/7 [==============================] - 5s 769ms/step - loss: 0.0015 - macro_f1: 0.9992 - val_loss: 0.0059 - val_macro_f1: 0.9951\n",
            "Epoch 99/200\n",
            "7/7 [==============================] - 4s 686ms/step - loss: 0.0014 - macro_f1: 0.9992 - val_loss: 0.0058 - val_macro_f1: 0.9951\n",
            "Epoch 100/200\n",
            "7/7 [==============================] - 4s 611ms/step - loss: 0.0014 - macro_f1: 0.9993 - val_loss: 0.0058 - val_macro_f1: 0.9951\n",
            "Epoch 101/200\n",
            "7/7 [==============================] - 5s 718ms/step - loss: 0.0013 - macro_f1: 0.9994 - val_loss: 0.0058 - val_macro_f1: 0.9951\n",
            "Epoch 102/200\n",
            "7/7 [==============================] - 5s 706ms/step - loss: 0.0014 - macro_f1: 0.9993 - val_loss: 0.0058 - val_macro_f1: 0.9951\n",
            "Epoch 103/200\n",
            "7/7 [==============================] - 5s 734ms/step - loss: 0.0014 - macro_f1: 0.9993 - val_loss: 0.0058 - val_macro_f1: 0.9951\n",
            "Epoch 104/200\n",
            "7/7 [==============================] - 4s 624ms/step - loss: 0.0014 - macro_f1: 0.9992 - val_loss: 0.0057 - val_macro_f1: 0.9951\n",
            "Epoch 105/200\n",
            "7/7 [==============================] - 5s 721ms/step - loss: 0.0014 - macro_f1: 0.9992 - val_loss: 0.0057 - val_macro_f1: 0.9951\n",
            "Epoch 106/200\n",
            "7/7 [==============================] - 4s 624ms/step - loss: 0.0013 - macro_f1: 0.9994 - val_loss: 0.0057 - val_macro_f1: 0.9951\n",
            "Epoch 107/200\n",
            "7/7 [==============================] - 5s 719ms/step - loss: 0.0013 - macro_f1: 0.9993 - val_loss: 0.0057 - val_macro_f1: 0.9951\n",
            "Epoch 108/200\n",
            "7/7 [==============================] - 5s 752ms/step - loss: 0.0012 - macro_f1: 0.9994 - val_loss: 0.0057 - val_macro_f1: 0.9951\n",
            "Epoch 109/200\n",
            "7/7 [==============================] - 5s 783ms/step - loss: 0.0014 - macro_f1: 0.9991 - val_loss: 0.0056 - val_macro_f1: 0.9951\n",
            "Epoch 110/200\n",
            "7/7 [==============================] - 5s 789ms/step - loss: 0.0012 - macro_f1: 0.9992 - val_loss: 0.0056 - val_macro_f1: 0.9951\n",
            "Epoch 111/200\n",
            "7/7 [==============================] - 4s 578ms/step - loss: 0.0012 - macro_f1: 0.9994 - val_loss: 0.0056 - val_macro_f1: 0.9951\n",
            "Epoch 112/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0012 - macro_f1: 0.9993 - val_loss: 0.0056 - val_macro_f1: 0.9951\n",
            "Epoch 113/200\n",
            "7/7 [==============================] - 5s 714ms/step - loss: 0.0012 - macro_f1: 0.9993 - val_loss: 0.0056 - val_macro_f1: 0.9951\n",
            "Epoch 114/200\n",
            "7/7 [==============================] - 5s 772ms/step - loss: 0.0012 - macro_f1: 0.9994 - val_loss: 0.0056 - val_macro_f1: 0.9951\n",
            "Epoch 115/200\n",
            "7/7 [==============================] - 5s 709ms/step - loss: 0.0012 - macro_f1: 0.9993 - val_loss: 0.0056 - val_macro_f1: 0.9951\n",
            "Epoch 116/200\n",
            "7/7 [==============================] - 4s 557ms/step - loss: 0.0012 - macro_f1: 0.9994 - val_loss: 0.0055 - val_macro_f1: 0.9951\n",
            "Epoch 117/200\n",
            "7/7 [==============================] - 5s 764ms/step - loss: 0.0011 - macro_f1: 0.9994 - val_loss: 0.0055 - val_macro_f1: 0.9951\n",
            "Epoch 118/200\n",
            "7/7 [==============================] - 5s 780ms/step - loss: 0.0012 - macro_f1: 0.9993 - val_loss: 0.0055 - val_macro_f1: 0.9951\n",
            "Epoch 119/200\n",
            "7/7 [==============================] - 5s 744ms/step - loss: 0.0011 - macro_f1: 0.9993 - val_loss: 0.0055 - val_macro_f1: 0.9951\n",
            "Epoch 120/200\n",
            "7/7 [==============================] - 4s 585ms/step - loss: 0.0012 - macro_f1: 0.9993 - val_loss: 0.0055 - val_macro_f1: 0.9951\n",
            "Epoch 121/200\n",
            "7/7 [==============================] - 5s 717ms/step - loss: 0.0011 - macro_f1: 0.9994 - val_loss: 0.0055 - val_macro_f1: 0.9951\n",
            "Epoch 122/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0012 - macro_f1: 0.9992 - val_loss: 0.0055 - val_macro_f1: 0.9951\n",
            "Epoch 123/200\n",
            "7/7 [==============================] - 4s 563ms/step - loss: 0.0013 - macro_f1: 0.9992 - val_loss: 0.0054 - val_macro_f1: 0.9951\n",
            "Epoch 124/200\n",
            "7/7 [==============================] - 4s 610ms/step - loss: 0.0011 - macro_f1: 0.9994 - val_loss: 0.0054 - val_macro_f1: 0.9951\n",
            "Epoch 125/200\n",
            "7/7 [==============================] - 5s 683ms/step - loss: 0.0012 - macro_f1: 0.9992 - val_loss: 0.0054 - val_macro_f1: 0.9951\n",
            "Epoch 126/200\n",
            "7/7 [==============================] - 5s 718ms/step - loss: 0.0011 - macro_f1: 0.9993 - val_loss: 0.0054 - val_macro_f1: 0.9951\n",
            "Epoch 127/200\n",
            "7/7 [==============================] - 5s 717ms/step - loss: 0.0011 - macro_f1: 0.9994 - val_loss: 0.0054 - val_macro_f1: 0.9951\n",
            "Epoch 128/200\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.0011 - macro_f1: 0.9993 - val_loss: 0.0054 - val_macro_f1: 0.9951\n",
            "Epoch 129/200\n",
            "7/7 [==============================] - 4s 574ms/step - loss: 0.0013 - macro_f1: 0.9991 - val_loss: 0.0054 - val_macro_f1: 0.9951\n",
            "Epoch 130/200\n",
            "7/7 [==============================] - 5s 708ms/step - loss: 0.0010 - macro_f1: 0.9994 - val_loss: 0.0053 - val_macro_f1: 0.9951\n",
            "Epoch 131/200\n",
            "7/7 [==============================] - 5s 754ms/step - loss: 0.0010 - macro_f1: 0.9994 - val_loss: 0.0053 - val_macro_f1: 0.9951\n",
            "Epoch 132/200\n",
            "7/7 [==============================] - 5s 704ms/step - loss: 0.0011 - macro_f1: 0.9993 - val_loss: 0.0053 - val_macro_f1: 0.9951\n",
            "Epoch 133/200\n",
            "7/7 [==============================] - 6s 843ms/step - loss: 0.0011 - macro_f1: 0.9993 - val_loss: 0.0053 - val_macro_f1: 0.9951\n",
            "Epoch 134/200\n",
            "7/7 [==============================] - 4s 564ms/step - loss: 0.0011 - macro_f1: 0.9991 - val_loss: 0.0053 - val_macro_f1: 0.9951\n",
            "Epoch 135/200\n",
            "7/7 [==============================] - 5s 709ms/step - loss: 0.0010 - macro_f1: 0.9994 - val_loss: 0.0053 - val_macro_f1: 0.9951\n",
            "Epoch 136/200\n",
            "7/7 [==============================] - 5s 768ms/step - loss: 0.0011 - macro_f1: 0.9993 - val_loss: 0.0053 - val_macro_f1: 0.9951\n",
            "Epoch 137/200\n",
            "7/7 [==============================] - 5s 719ms/step - loss: 0.0010 - macro_f1: 0.9994 - val_loss: 0.0053 - val_macro_f1: 0.9951\n",
            "Epoch 138/200\n",
            "7/7 [==============================] - 5s 788ms/step - loss: 0.0011 - macro_f1: 0.9993 - val_loss: 0.0053 - val_macro_f1: 0.9951\n",
            "Epoch 139/200\n",
            "7/7 [==============================] - 5s 737ms/step - loss: 9.9921e-04 - macro_f1: 0.9994 - val_loss: 0.0053 - val_macro_f1: 0.9951\n",
            "Epoch 140/200\n",
            "7/7 [==============================] - 5s 709ms/step - loss: 0.0011 - macro_f1: 0.9993 - val_loss: 0.0052 - val_macro_f1: 0.9959\n",
            "Epoch 141/200\n",
            "7/7 [==============================] - 5s 741ms/step - loss: 0.0011 - macro_f1: 0.9993 - val_loss: 0.0052 - val_macro_f1: 0.9951\n",
            "Epoch 142/200\n",
            "7/7 [==============================] - 4s 593ms/step - loss: 0.0011 - macro_f1: 0.9991 - val_loss: 0.0052 - val_macro_f1: 0.9951\n",
            "Epoch 143/200\n",
            "7/7 [==============================] - 5s 707ms/step - loss: 0.0011 - macro_f1: 0.9993 - val_loss: 0.0052 - val_macro_f1: 0.9951\n",
            "Epoch 144/200\n",
            "7/7 [==============================] - 5s 685ms/step - loss: 0.0010 - macro_f1: 0.9993 - val_loss: 0.0052 - val_macro_f1: 0.9951\n",
            "Epoch 145/200\n",
            "7/7 [==============================] - 5s 746ms/step - loss: 0.0010 - macro_f1: 0.9993 - val_loss: 0.0052 - val_macro_f1: 0.9951\n",
            "Epoch 146/200\n",
            "7/7 [==============================] - 5s 704ms/step - loss: 0.0010 - macro_f1: 0.9991 - val_loss: 0.0052 - val_macro_f1: 0.9951\n",
            "Epoch 147/200\n",
            "7/7 [==============================] - 4s 633ms/step - loss: 0.0010 - macro_f1: 0.9993 - val_loss: 0.0052 - val_macro_f1: 0.9951\n",
            "Epoch 148/200\n",
            "7/7 [==============================] - 4s 645ms/step - loss: 0.0010 - macro_f1: 0.9993 - val_loss: 0.0052 - val_macro_f1: 0.9951\n",
            "Epoch 149/200\n",
            "7/7 [==============================] - 4s 640ms/step - loss: 0.0010 - macro_f1: 0.9993 - val_loss: 0.0052 - val_macro_f1: 0.9951\n",
            "Epoch 150/200\n",
            "7/7 [==============================] - 5s 729ms/step - loss: 0.0010 - macro_f1: 0.9993 - val_loss: 0.0052 - val_macro_f1: 0.9951\n",
            "Epoch 151/200\n",
            "7/7 [==============================] - 5s 752ms/step - loss: 0.0010 - macro_f1: 0.9993 - val_loss: 0.0052 - val_macro_f1: 0.9959\n",
            "Epoch 152/200\n",
            "7/7 [==============================] - 5s 705ms/step - loss: 9.7432e-04 - macro_f1: 0.9993 - val_loss: 0.0052 - val_macro_f1: 0.9951\n",
            "Epoch 153/200\n",
            "7/7 [==============================] - 5s 724ms/step - loss: 9.6715e-04 - macro_f1: 0.9993 - val_loss: 0.0051 - val_macro_f1: 0.9951\n",
            "Epoch 154/200\n",
            "7/7 [==============================] - 5s 764ms/step - loss: 0.0012 - macro_f1: 0.9992 - val_loss: 0.0051 - val_macro_f1: 0.9951\n",
            "Epoch 155/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 9.9672e-04 - macro_f1: 0.9992 - val_loss: 0.0051 - val_macro_f1: 0.9951\n",
            "Epoch 156/200\n",
            "7/7 [==============================] - 4s 661ms/step - loss: 9.4486e-04 - macro_f1: 0.9994 - val_loss: 0.0051 - val_macro_f1: 0.9951\n",
            "Epoch 157/200\n",
            "7/7 [==============================] - 5s 713ms/step - loss: 0.0010 - macro_f1: 0.9993 - val_loss: 0.0051 - val_macro_f1: 0.9951\n",
            "Epoch 158/200\n",
            "7/7 [==============================] - 4s 555ms/step - loss: 9.5209e-04 - macro_f1: 0.9993 - val_loss: 0.0051 - val_macro_f1: 0.9951\n",
            "Epoch 159/200\n",
            "7/7 [==============================] - 5s 774ms/step - loss: 9.5700e-04 - macro_f1: 0.9993 - val_loss: 0.0051 - val_macro_f1: 0.9959\n",
            "Epoch 160/200\n",
            "7/7 [==============================] - 5s 704ms/step - loss: 9.5337e-04 - macro_f1: 0.9993 - val_loss: 0.0051 - val_macro_f1: 0.9959\n",
            "Epoch 161/200\n",
            "7/7 [==============================] - 4s 600ms/step - loss: 0.0011 - macro_f1: 0.9991 - val_loss: 0.0051 - val_macro_f1: 0.9951\n",
            "Epoch 162/200\n",
            "7/7 [==============================] - 5s 742ms/step - loss: 9.2572e-04 - macro_f1: 0.9994 - val_loss: 0.0051 - val_macro_f1: 0.9951\n",
            "Epoch 163/200\n",
            "7/7 [==============================] - 4s 570ms/step - loss: 9.3694e-04 - macro_f1: 0.9993 - val_loss: 0.0051 - val_macro_f1: 0.9951\n",
            "Epoch 164/200\n",
            "7/7 [==============================] - 5s 720ms/step - loss: 9.9945e-04 - macro_f1: 0.9993 - val_loss: 0.0051 - val_macro_f1: 0.9959\n",
            "Epoch 165/200\n",
            "7/7 [==============================] - 4s 609ms/step - loss: 9.5650e-04 - macro_f1: 0.9993 - val_loss: 0.0050 - val_macro_f1: 0.9959\n",
            "Epoch 166/200\n",
            "7/7 [==============================] - 5s 764ms/step - loss: 9.1199e-04 - macro_f1: 0.9994 - val_loss: 0.0050 - val_macro_f1: 0.9959\n",
            "Epoch 167/200\n",
            "7/7 [==============================] - 4s 651ms/step - loss: 9.3276e-04 - macro_f1: 0.9993 - val_loss: 0.0050 - val_macro_f1: 0.9951\n",
            "Epoch 168/200\n",
            "7/7 [==============================] - 4s 588ms/step - loss: 9.2745e-04 - macro_f1: 0.9993 - val_loss: 0.0050 - val_macro_f1: 0.9951\n",
            "Epoch 169/200\n",
            "7/7 [==============================] - 4s 560ms/step - loss: 9.2008e-04 - macro_f1: 0.9993 - val_loss: 0.0050 - val_macro_f1: 0.9959\n",
            "Epoch 170/200\n",
            "7/7 [==============================] - 4s 558ms/step - loss: 9.0821e-04 - macro_f1: 0.9993 - val_loss: 0.0050 - val_macro_f1: 0.9959\n",
            "Epoch 171/200\n",
            "7/7 [==============================] - 5s 752ms/step - loss: 8.6180e-04 - macro_f1: 0.9994 - val_loss: 0.0050 - val_macro_f1: 0.9959\n",
            "Epoch 172/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 8.5239e-04 - macro_f1: 0.9994 - val_loss: 0.0050 - val_macro_f1: 0.9959\n",
            "Epoch 173/200\n",
            "7/7 [==============================] - 4s 649ms/step - loss: 9.8279e-04 - macro_f1: 0.9993 - val_loss: 0.0050 - val_macro_f1: 0.9951\n",
            "Epoch 174/200\n",
            "7/7 [==============================] - 5s 718ms/step - loss: 0.0010 - macro_f1: 0.9992 - val_loss: 0.0050 - val_macro_f1: 0.9959\n",
            "Epoch 175/200\n",
            "7/7 [==============================] - 4s 638ms/step - loss: 9.5086e-04 - macro_f1: 0.9993 - val_loss: 0.0050 - val_macro_f1: 0.9951\n",
            "Epoch 176/200\n",
            "7/7 [==============================] - 5s 736ms/step - loss: 9.1463e-04 - macro_f1: 0.9993 - val_loss: 0.0050 - val_macro_f1: 0.9951\n",
            "Epoch 177/200\n",
            "7/7 [==============================] - 5s 756ms/step - loss: 9.8685e-04 - macro_f1: 0.9993 - val_loss: 0.0050 - val_macro_f1: 0.9951\n",
            "Epoch 178/200\n",
            "7/7 [==============================] - 5s 739ms/step - loss: 8.7909e-04 - macro_f1: 0.9994 - val_loss: 0.0050 - val_macro_f1: 0.9951\n",
            "Epoch 179/200\n",
            "7/7 [==============================] - 5s 718ms/step - loss: 8.6484e-04 - macro_f1: 0.9994 - val_loss: 0.0050 - val_macro_f1: 0.9959\n",
            "Epoch 180/200\n",
            "7/7 [==============================] - 5s 717ms/step - loss: 9.6713e-04 - macro_f1: 0.9993 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 181/200\n",
            "7/7 [==============================] - 5s 773ms/step - loss: 9.2734e-04 - macro_f1: 0.9993 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 182/200\n",
            "7/7 [==============================] - 5s 722ms/step - loss: 9.2305e-04 - macro_f1: 0.9993 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 183/200\n",
            "7/7 [==============================] - 4s 595ms/step - loss: 8.4902e-04 - macro_f1: 0.9994 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 184/200\n",
            "7/7 [==============================] - 5s 775ms/step - loss: 8.5491e-04 - macro_f1: 0.9992 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 185/200\n",
            "7/7 [==============================] - 5s 719ms/step - loss: 8.8631e-04 - macro_f1: 0.9993 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 186/200\n",
            "7/7 [==============================] - 5s 714ms/step - loss: 8.3672e-04 - macro_f1: 0.9994 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 187/200\n",
            "7/7 [==============================] - 5s 774ms/step - loss: 8.4757e-04 - macro_f1: 0.9994 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 188/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 9.5943e-04 - macro_f1: 0.9993 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 189/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 8.4449e-04 - macro_f1: 0.9994 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 190/200\n",
            "7/7 [==============================] - 4s 557ms/step - loss: 8.5704e-04 - macro_f1: 0.9994 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 191/200\n",
            "7/7 [==============================] - 5s 716ms/step - loss: 8.0205e-04 - macro_f1: 0.9994 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 192/200\n",
            "7/7 [==============================] - 5s 751ms/step - loss: 9.4114e-04 - macro_f1: 0.9993 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 193/200\n",
            "7/7 [==============================] - 5s 752ms/step - loss: 8.9075e-04 - macro_f1: 0.9993 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 194/200\n",
            "7/7 [==============================] - 4s 584ms/step - loss: 8.6534e-04 - macro_f1: 0.9993 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 195/200\n",
            "7/7 [==============================] - 5s 751ms/step - loss: 8.3093e-04 - macro_f1: 0.9994 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 196/200\n",
            "7/7 [==============================] - 5s 710ms/step - loss: 8.3516e-04 - macro_f1: 0.9993 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 197/200\n",
            "7/7 [==============================] - 4s 560ms/step - loss: 9.1705e-04 - macro_f1: 0.9993 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 198/200\n",
            "7/7 [==============================] - 5s 738ms/step - loss: 8.9469e-04 - macro_f1: 0.9993 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 199/200\n",
            "7/7 [==============================] - 4s 599ms/step - loss: 9.6041e-04 - macro_f1: 0.9992 - val_loss: 0.0049 - val_macro_f1: 0.9959\n",
            "Epoch 200/200\n",
            "7/7 [==============================] - 4s 651ms/step - loss: 8.5873e-04 - macro_f1: 0.9993 - val_loss: 0.0049 - val_macro_f1: 0.9959\n"
          ]
        }
      ],
      "source": [
        "LR = 1e-4 # Keep it small when transfer learning\n",
        "EPOCHS = 200\n",
        "PATIENCE=5\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor = 'val_loss', patience = PATIENCE)\n",
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
        "  loss=macro_soft_f1,\n",
        "  metrics=[macro_f1])\n",
        "# Train the model\n",
        "history = model.fit(train_ds1,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=create_dataset(X_val, y_val_bin,\n",
        "                                                   is_training=False),callbacks = [early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3zHJhgFt7Sq"
      },
      "outputs": [],
      "source": [
        "X,y=val_ds1\n",
        "images=X[0]\n",
        "labels=np.array(X[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfPsBEGs9EYJ",
        "outputId": "a8e881d4-a0ce-4a94-9478-f0b6b9eb9e15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 1, ..., 0, 0, 0],\n",
              "       [0, 1, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 1, ..., 0, 0, 0]])"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw-D3G9JwURZ",
        "outputId": "ce62d0ab-cb80-41d3-83a8-6b6120d33336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 1s 48ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions=np.array(model.predict(images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMMqg2qH8_02",
        "outputId": "d5244d2c-1972-4849-c9a4-4d440e409e80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([1.10601924e-07, 3.05853405e-06, 3.65717057e-08, 8.41973178e-06,\n",
              "        7.31259206e-07, 3.00365082e-06, 5.42069188e-07, 3.62936028e-08,\n",
              "        1.43271819e-07, 9.99999881e-01, 2.67302426e-07, 1.64907044e-06],\n",
              "       dtype=float32)]"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[predictions[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PxXrVrLw0Im"
      },
      "outputs": [],
      "source": [
        "# Define the threshold\n",
        "threshold = 0.5\n",
        "\n",
        "# Convert values to binary array based on the threshold\n",
        "binary_array = np.where(np.array(predictions) > threshold, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WE6rhNM1Iv2"
      },
      "outputs": [],
      "source": [
        "predicted_labels=mlb.inverse_transform(binary_array)\n",
        "actual_labels=mlb.inverse_transform(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7fbCv5A9YwS",
        "outputId": "40c0f029-5b4e-4851-c7a6-503f8dc89d95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('sloth',),\n",
              " ('giraffe', 'green'),\n",
              " ('alarm',),\n",
              " ('crane', 'green'),\n",
              " ('pink', 'snake'),\n",
              " ('sloth',),\n",
              " ('crane', 'grey'),\n",
              " ('crane', 'yellow'),\n",
              " ('pink', 'snake'),\n",
              " ('crane', 'yellow'),\n",
              " ('alarm',),\n",
              " ('alarm',),\n",
              " ('sloth',),\n",
              " ('blue', 'lion'),\n",
              " ('giraffe', 'pink'),\n",
              " ('crane', 'yellow'),\n",
              " ('green', 'snake'),\n",
              " ('blue', 'giraffe'),\n",
              " ('crane', 'green'),\n",
              " ('blue', 'snake'),\n",
              " ('sloth',),\n",
              " ('blue', 'crane'),\n",
              " ('blue', 'lion'),\n",
              " ('monkey', 'pink'),\n",
              " ('blue', 'snake'),\n",
              " ('giraffe', 'pink'),\n",
              " ('sloth',),\n",
              " ('crane', 'pink'),\n",
              " ('blue', 'giraffe'),\n",
              " ('grey', 'monkey'),\n",
              " ('alarm',),\n",
              " ('pink', 'snake'),\n",
              " ('grey', 'snake'),\n",
              " ('crane', 'grey'),\n",
              " ('blue', 'snake'),\n",
              " ('crane', 'grey'),\n",
              " ('grey', 'monkey'),\n",
              " ('blue', 'monkey'),\n",
              " ('blue', 'monkey'),\n",
              " ('blue', 'giraffe'),\n",
              " ('green', 'lion'),\n",
              " ('grey', 'snake'),\n",
              " ('giraffe', 'pink'),\n",
              " ('giraffe', 'green'),\n",
              " ('alarm',),\n",
              " ('green', 'monkey'),\n",
              " ('sloth',),\n",
              " ('giraffe', 'pink'),\n",
              " ('giraffe', 'green'),\n",
              " ('giraffe', 'yellow'),\n",
              " ('grey', 'snake'),\n",
              " ('crane', 'pink'),\n",
              " ('crane', 'grey'),\n",
              " ('grey', 'snake'),\n",
              " ('monkey', 'yellow'),\n",
              " ('snake', 'yellow'),\n",
              " ('blue', 'lion'),\n",
              " ('blue', 'giraffe'),\n",
              " ('green', 'lion'),\n",
              " ('lion', 'pink'),\n",
              " ('alarm',),\n",
              " ('sloth',),\n",
              " ('giraffe', 'pink'),\n",
              " ('giraffe', 'green'),\n",
              " ('green', 'monkey'),\n",
              " ('crane', 'yellow'),\n",
              " ('green', 'monkey'),\n",
              " ('giraffe', 'yellow'),\n",
              " ('blue', 'snake'),\n",
              " ('alarm',),\n",
              " ('blue', 'crane'),\n",
              " ('giraffe', 'green'),\n",
              " ('pink', 'snake'),\n",
              " ('giraffe', 'pink'),\n",
              " ('lion', 'yellow'),\n",
              " ('sloth',),\n",
              " ('blue', 'monkey'),\n",
              " ('blue', 'giraffe'),\n",
              " ('crane', 'green'),\n",
              " ('alarm',),\n",
              " ('grey', 'snake'),\n",
              " ('grey', 'snake'),\n",
              " ('grey', 'monkey'),\n",
              " ('crane', 'green', 'grey'),\n",
              " ('pink', 'snake'),\n",
              " ('sloth',),\n",
              " ('snake', 'yellow'),\n",
              " ('lion', 'pink'),\n",
              " ('sloth',),\n",
              " ('grey', 'snake'),\n",
              " ('grey', 'monkey'),\n",
              " ('monkey', 'yellow'),\n",
              " ('sloth',),\n",
              " ('alarm',),\n",
              " ('crane', 'green'),\n",
              " ('green', 'lion'),\n",
              " ('sloth',),\n",
              " ('grey', 'lion'),\n",
              " ('green', 'lion'),\n",
              " ('green', 'monkey'),\n",
              " ('crane', 'yellow'),\n",
              " ('crane', 'pink'),\n",
              " ('lion', 'pink'),\n",
              " ('alarm',),\n",
              " ('crane', 'yellow'),\n",
              " ('blue', 'giraffe'),\n",
              " ('grey', 'snake'),\n",
              " ('sloth',),\n",
              " ('giraffe', 'pink'),\n",
              " ('blue', 'monkey'),\n",
              " ('blue', 'lion'),\n",
              " ('blue', 'snake'),\n",
              " ('alarm',),\n",
              " ('lion', 'yellow'),\n",
              " ('green', 'lion'),\n",
              " ('grey', 'lion'),\n",
              " ('grey', 'lion'),\n",
              " ('blue', 'lion'),\n",
              " ('alarm',),\n",
              " ('sloth',),\n",
              " ('green', 'lion'),\n",
              " ('snake', 'yellow'),\n",
              " ('crane', 'pink'),\n",
              " ('green', 'lion'),\n",
              " ('grey', 'lion'),\n",
              " ('lion', 'pink'),\n",
              " ('monkey', 'pink'),\n",
              " ('crane', 'green'),\n",
              " ('giraffe', 'green'),\n",
              " ('lion', 'pink'),\n",
              " ('green', 'snake'),\n",
              " ('grey', 'lion'),\n",
              " ('giraffe', 'pink'),\n",
              " ('grey', 'snake'),\n",
              " ('sloth',),\n",
              " ('blue', 'lion'),\n",
              " ('crane', 'pink'),\n",
              " ('alarm',),\n",
              " ('alarm',),\n",
              " ('blue', 'giraffe'),\n",
              " ('green', 'monkey'),\n",
              " ('sloth',),\n",
              " ('grey', 'monkey'),\n",
              " ('monkey', 'yellow'),\n",
              " ('crane', 'yellow'),\n",
              " ('crane', 'yellow'),\n",
              " ('pink', 'snake'),\n",
              " ('green', 'monkey'),\n",
              " ('crane', 'pink'),\n",
              " ('giraffe', 'grey'),\n",
              " ('green', 'monkey'),\n",
              " ('green', 'lion'),\n",
              " ('alarm',),\n",
              " ('green', 'snake'),\n",
              " ('blue', 'crane'),\n",
              " ('green', 'lion'),\n",
              " ('alarm',),\n",
              " ('giraffe', 'pink'),\n",
              " ('monkey', 'pink'),\n",
              " ('crane', 'green'),\n",
              " ('green', 'snake'),\n",
              " ('sloth',),\n",
              " ('crane', 'yellow'),\n",
              " ('blue', 'crane'),\n",
              " ('monkey', 'pink'),\n",
              " ('grey', 'lion'),\n",
              " ('alarm',),\n",
              " ('crane', 'pink'),\n",
              " ('sloth',),\n",
              " ('green', 'monkey'),\n",
              " ('blue', 'lion'),\n",
              " ('snake', 'yellow'),\n",
              " ('grey', 'snake'),\n",
              " ('pink', 'snake'),\n",
              " ('lion', 'yellow'),\n",
              " ('blue', 'lion'),\n",
              " ('alarm',),\n",
              " ('giraffe', 'green'),\n",
              " ('alarm',),\n",
              " ('monkey', 'pink'),\n",
              " ('monkey', 'pink'),\n",
              " ('monkey', 'pink'),\n",
              " ('green', 'snake'),\n",
              " ('alarm',),\n",
              " ('sloth',),\n",
              " ('crane', 'green'),\n",
              " ('sloth',),\n",
              " ('lion', 'yellow'),\n",
              " ('green', 'monkey'),\n",
              " ('grey', 'monkey'),\n",
              " ('giraffe', 'grey'),\n",
              " ('green', 'snake'),\n",
              " ('blue', 'crane'),\n",
              " ('alarm',),\n",
              " ('monkey', 'pink'),\n",
              " ('lion', 'yellow'),\n",
              " ('blue', 'monkey'),\n",
              " ('giraffe', 'grey'),\n",
              " ('green', 'monkey'),\n",
              " ('giraffe', 'green'),\n",
              " ('crane', 'yellow'),\n",
              " ('monkey', 'pink'),\n",
              " ('giraffe', 'grey'),\n",
              " ('grey', 'snake'),\n",
              " ('crane', 'grey'),\n",
              " ('blue', 'lion'),\n",
              " ('pink', 'snake'),\n",
              " ('lion', 'yellow'),\n",
              " ('crane', 'grey'),\n",
              " ('lion', 'pink'),\n",
              " ('alarm',),\n",
              " ('giraffe', 'grey'),\n",
              " ('lion', 'yellow'),\n",
              " ('green', 'lion'),\n",
              " ('blue', 'crane'),\n",
              " ('blue', 'lion'),\n",
              " ('giraffe', 'grey'),\n",
              " ('green', 'monkey'),\n",
              " ('alarm',),\n",
              " ('monkey', 'pink'),\n",
              " ('sloth',),\n",
              " ('blue', 'snake'),\n",
              " ('sloth',),\n",
              " ('sloth',),\n",
              " ('blue', 'monkey'),\n",
              " ('lion', 'pink'),\n",
              " ('blue', 'crane'),\n",
              " ('green', 'lion'),\n",
              " ('giraffe', 'green'),\n",
              " ('grey', 'monkey'),\n",
              " ('blue', 'giraffe'),\n",
              " ('giraffe', 'pink'),\n",
              " ('alarm',),\n",
              " ('green', 'snake'),\n",
              " ('alarm',),\n",
              " ('grey', 'lion'),\n",
              " ('alarm',),\n",
              " ('blue', 'lion'),\n",
              " ('lion', 'pink'),\n",
              " ('green', 'monkey'),\n",
              " ('green', 'monkey'),\n",
              " ('crane', 'yellow'),\n",
              " ('blue', 'crane'),\n",
              " ('sloth',),\n",
              " ('grey', 'lion'),\n",
              " ('grey', 'snake'),\n",
              " ('monkey', 'pink'),\n",
              " ('monkey', 'pink'),\n",
              " ('blue', 'snake'),\n",
              " ('monkey', 'yellow'),\n",
              " ('crane', 'grey'),\n",
              " ('lion', 'yellow'),\n",
              " ('grey', 'lion'),\n",
              " ('crane', 'green'),\n",
              " ('blue', 'giraffe'),\n",
              " ('crane', 'green')]"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HztY95yR2s14",
        "outputId": "3a068cd3-c95e-4f33-adc1-209681711cde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('sloth',) ('sloth',)\n",
            "('giraffe', 'green') ('giraffe', 'green')\n",
            "('alarm',) ('alarm',)\n",
            "('crane', 'green') ('crane', 'green')\n",
            "('pink', 'snake') ('pink', 'snake')\n",
            "('sloth',) ('sloth',)\n",
            "('grey', 'monkey') ('crane', 'grey')\n",
            "('crane', 'yellow') ('crane', 'yellow')\n",
            "('pink', 'snake') ('pink', 'snake')\n",
            "('crane', 'yellow') ('crane', 'yellow')\n",
            "('alarm',) ('alarm',)\n",
            "('alarm',) ('alarm',)\n",
            "('sloth',) ('sloth',)\n",
            "('blue', 'lion') ('blue', 'lion')\n",
            "('giraffe', 'pink') ('giraffe', 'pink')\n",
            "('crane', 'yellow') ('crane', 'yellow')\n",
            "('green', 'snake') ('green', 'snake')\n",
            "('blue', 'giraffe') ('blue', 'giraffe')\n",
            "('crane', 'green') ('crane', 'green')\n",
            "('blue', 'snake') ('blue', 'snake')\n",
            "('sloth',) ('sloth',)\n",
            "('blue', 'crane') ('blue', 'crane')\n",
            "('blue', 'lion') ('blue', 'lion')\n",
            "('monkey', 'pink') ('monkey', 'pink')\n",
            "('blue', 'snake') ('blue', 'snake')\n",
            "('giraffe', 'pink') ('giraffe', 'pink')\n",
            "('sloth',) ('sloth',)\n",
            "('crane', 'pink') ('crane', 'pink')\n",
            "('blue', 'giraffe') ('blue', 'giraffe')\n",
            "('grey', 'monkey') ('grey', 'monkey')\n",
            "('alarm',) ('alarm',)\n",
            "('pink', 'snake') ('pink', 'snake')\n",
            "('grey', 'snake') ('grey', 'snake')\n",
            "('crane', 'grey') ('crane', 'grey')\n",
            "('blue', 'snake') ('blue', 'snake')\n",
            "('crane', 'grey') ('crane', 'grey')\n",
            "('grey', 'monkey') ('grey', 'monkey')\n",
            "('blue', 'monkey') ('blue', 'monkey')\n",
            "('blue', 'monkey') ('blue', 'monkey')\n",
            "('blue', 'giraffe') ('blue', 'giraffe')\n",
            "('green', 'lion') ('green', 'lion')\n",
            "('grey', 'snake') ('grey', 'snake')\n",
            "('giraffe', 'pink') ('giraffe', 'pink')\n",
            "('giraffe', 'green') ('giraffe', 'green')\n",
            "('alarm',) ('alarm',)\n",
            "('green', 'monkey') ('green', 'monkey')\n",
            "('sloth',) ('sloth',)\n",
            "('giraffe', 'pink') ('giraffe', 'pink')\n",
            "('giraffe', 'green') ('giraffe', 'green')\n",
            "('giraffe', 'yellow') ('giraffe', 'yellow')\n",
            "('grey', 'snake') ('grey', 'snake')\n",
            "('crane', 'pink') ('crane', 'pink')\n",
            "('crane', 'grey') ('crane', 'grey')\n",
            "('grey', 'snake') ('grey', 'snake')\n",
            "('monkey', 'yellow') ('monkey', 'yellow')\n",
            "('snake', 'yellow') ('snake', 'yellow')\n",
            "('blue', 'lion') ('blue', 'lion')\n",
            "('blue', 'giraffe') ('blue', 'giraffe')\n",
            "('green', 'lion') ('green', 'lion')\n",
            "('lion', 'pink') ('lion', 'pink')\n",
            "('alarm',) ('alarm',)\n",
            "('sloth',) ('sloth',)\n",
            "('giraffe', 'pink') ('giraffe', 'pink')\n",
            "('giraffe', 'green') ('giraffe', 'green')\n",
            "('green', 'monkey') ('green', 'monkey')\n",
            "('crane', 'yellow') ('crane', 'yellow')\n",
            "('green', 'monkey') ('green', 'monkey')\n",
            "('giraffe', 'yellow') ('giraffe', 'yellow')\n",
            "('blue', 'snake') ('blue', 'snake')\n",
            "('alarm',) ('alarm',)\n",
            "('blue', 'crane') ('blue', 'crane')\n",
            "('giraffe', 'green') ('giraffe', 'green')\n",
            "('pink', 'snake') ('pink', 'snake')\n",
            "('giraffe', 'pink') ('giraffe', 'pink')\n",
            "('lion', 'yellow') ('lion', 'yellow')\n",
            "('sloth',) ('sloth',)\n",
            "('blue', 'monkey') ('blue', 'monkey')\n",
            "('blue', 'giraffe') ('blue', 'giraffe')\n",
            "('crane', 'green') ('crane', 'green')\n",
            "('alarm',) ('alarm',)\n",
            "('grey', 'snake') ('grey', 'snake')\n",
            "('grey', 'snake') ('grey', 'snake')\n",
            "('grey', 'monkey') ('grey', 'monkey')\n",
            "('crane', 'green') ('crane', 'green', 'grey')\n",
            "('pink', 'snake') ('pink', 'snake')\n",
            "('sloth',) ('sloth',)\n",
            "('snake', 'yellow') ('snake', 'yellow')\n",
            "('lion', 'pink') ('lion', 'pink')\n",
            "('sloth',) ('sloth',)\n",
            "('grey', 'snake') ('grey', 'snake')\n",
            "('grey', 'monkey') ('grey', 'monkey')\n",
            "('monkey', 'yellow') ('monkey', 'yellow')\n",
            "('sloth',) ('sloth',)\n",
            "('alarm',) ('alarm',)\n",
            "('crane', 'green') ('crane', 'green')\n",
            "('green', 'lion') ('green', 'lion')\n",
            "('sloth',) ('sloth',)\n",
            "('grey', 'lion') ('grey', 'lion')\n",
            "('green', 'lion') ('green', 'lion')\n",
            "('green', 'monkey') ('green', 'monkey')\n",
            "('crane', 'yellow') ('crane', 'yellow')\n",
            "('crane', 'pink') ('crane', 'pink')\n",
            "('lion', 'pink') ('lion', 'pink')\n",
            "('alarm',) ('alarm',)\n",
            "('crane', 'yellow') ('crane', 'yellow')\n",
            "('blue', 'giraffe') ('blue', 'giraffe')\n",
            "('grey', 'snake') ('grey', 'snake')\n",
            "('sloth',) ('sloth',)\n",
            "('giraffe', 'pink') ('giraffe', 'pink')\n",
            "('blue', 'monkey') ('blue', 'monkey')\n",
            "('blue', 'lion') ('blue', 'lion')\n",
            "('blue', 'snake') ('blue', 'snake')\n",
            "('alarm',) ('alarm',)\n",
            "('lion', 'yellow') ('lion', 'yellow')\n",
            "('green', 'lion') ('green', 'lion')\n",
            "('grey', 'lion') ('grey', 'lion')\n",
            "('grey', 'lion') ('grey', 'lion')\n",
            "('blue', 'lion') ('blue', 'lion')\n",
            "('alarm',) ('alarm',)\n",
            "('sloth',) ('sloth',)\n",
            "('green', 'lion') ('green', 'lion')\n",
            "('snake', 'yellow') ('snake', 'yellow')\n",
            "('crane', 'pink') ('crane', 'pink')\n",
            "('green', 'lion') ('green', 'lion')\n",
            "('grey', 'lion') ('grey', 'lion')\n",
            "('lion', 'pink') ('lion', 'pink')\n",
            "('monkey', 'pink') ('monkey', 'pink')\n",
            "('crane', 'green') ('crane', 'green')\n",
            "('giraffe', 'green') ('giraffe', 'green')\n",
            "('lion', 'pink') ('lion', 'pink')\n",
            "('green', 'snake') ('green', 'snake')\n",
            "('grey', 'lion') ('grey', 'lion')\n",
            "('giraffe', 'pink') ('giraffe', 'pink')\n",
            "('grey', 'snake') ('grey', 'snake')\n",
            "('sloth',) ('sloth',)\n",
            "('blue', 'lion') ('blue', 'lion')\n",
            "('crane', 'pink') ('crane', 'pink')\n",
            "('alarm',) ('alarm',)\n",
            "('alarm',) ('alarm',)\n",
            "('blue', 'giraffe') ('blue', 'giraffe')\n",
            "('green', 'monkey') ('green', 'monkey')\n",
            "('sloth',) ('sloth',)\n",
            "('grey', 'monkey') ('grey', 'monkey')\n",
            "('monkey', 'yellow') ('monkey', 'yellow')\n",
            "('crane', 'yellow') ('crane', 'yellow')\n",
            "('crane', 'yellow') ('crane', 'yellow')\n",
            "('pink', 'snake') ('pink', 'snake')\n",
            "('green', 'monkey') ('green', 'monkey')\n",
            "('crane', 'pink') ('crane', 'pink')\n",
            "('giraffe', 'grey') ('giraffe', 'grey')\n",
            "('green', 'monkey') ('green', 'monkey')\n",
            "('green', 'lion') ('green', 'lion')\n",
            "('alarm',) ('alarm',)\n",
            "('green', 'snake') ('green', 'snake')\n",
            "('blue', 'crane') ('blue', 'crane')\n",
            "('green', 'lion') ('green', 'lion')\n",
            "('alarm',) ('alarm',)\n",
            "('giraffe', 'pink') ('giraffe', 'pink')\n",
            "('monkey', 'pink') ('monkey', 'pink')\n",
            "('crane', 'green') ('crane', 'green')\n",
            "('green', 'snake') ('green', 'snake')\n",
            "('sloth',) ('sloth',)\n",
            "('crane', 'yellow') ('crane', 'yellow')\n",
            "('blue', 'crane') ('blue', 'crane')\n",
            "('monkey', 'pink') ('monkey', 'pink')\n",
            "('grey', 'lion') ('grey', 'lion')\n",
            "('alarm',) ('alarm',)\n",
            "('crane', 'pink') ('crane', 'pink')\n",
            "('sloth',) ('sloth',)\n",
            "('green', 'monkey') ('green', 'monkey')\n",
            "('blue', 'lion') ('blue', 'lion')\n",
            "('snake', 'yellow') ('snake', 'yellow')\n",
            "('grey', 'snake') ('grey', 'snake')\n",
            "('pink', 'snake') ('pink', 'snake')\n",
            "('lion', 'yellow') ('lion', 'yellow')\n",
            "('blue', 'lion') ('blue', 'lion')\n",
            "('alarm',) ('alarm',)\n",
            "('giraffe', 'green') ('giraffe', 'green')\n",
            "('alarm',) ('alarm',)\n",
            "('monkey', 'pink') ('monkey', 'pink')\n",
            "('monkey', 'pink') ('monkey', 'pink')\n",
            "('monkey', 'pink') ('monkey', 'pink')\n",
            "('green', 'snake') ('green', 'snake')\n",
            "('alarm',) ('alarm',)\n",
            "('sloth',) ('sloth',)\n",
            "('crane', 'green') ('crane', 'green')\n",
            "('sloth',) ('sloth',)\n",
            "('lion', 'yellow') ('lion', 'yellow')\n",
            "('green', 'monkey') ('green', 'monkey')\n",
            "('grey', 'monkey') ('grey', 'monkey')\n",
            "('giraffe', 'grey') ('giraffe', 'grey')\n",
            "('green', 'snake') ('green', 'snake')\n",
            "('blue', 'crane') ('blue', 'crane')\n",
            "('alarm',) ('alarm',)\n",
            "('monkey', 'pink') ('monkey', 'pink')\n",
            "('lion', 'yellow') ('lion', 'yellow')\n",
            "('blue', 'monkey') ('blue', 'monkey')\n",
            "('giraffe', 'grey') ('giraffe', 'grey')\n",
            "('green', 'monkey') ('green', 'monkey')\n",
            "('giraffe', 'green') ('giraffe', 'green')\n",
            "('crane', 'yellow') ('crane', 'yellow')\n",
            "('monkey', 'pink') ('monkey', 'pink')\n",
            "('giraffe', 'grey') ('giraffe', 'grey')\n",
            "('grey', 'snake') ('grey', 'snake')\n",
            "('crane', 'grey') ('crane', 'grey')\n",
            "('blue', 'lion') ('blue', 'lion')\n",
            "('pink', 'snake') ('pink', 'snake')\n",
            "('lion', 'yellow') ('lion', 'yellow')\n",
            "('crane', 'grey') ('crane', 'grey')\n",
            "('lion', 'pink') ('lion', 'pink')\n",
            "('alarm',) ('alarm',)\n",
            "('giraffe', 'grey') ('giraffe', 'grey')\n",
            "('lion', 'yellow') ('lion', 'yellow')\n",
            "('green', 'lion') ('green', 'lion')\n",
            "('blue', 'crane') ('blue', 'crane')\n",
            "('blue', 'lion') ('blue', 'lion')\n",
            "('giraffe', 'grey') ('giraffe', 'grey')\n",
            "('green', 'monkey') ('green', 'monkey')\n",
            "('alarm',) ('alarm',)\n",
            "('monkey', 'pink') ('monkey', 'pink')\n",
            "('sloth',) ('sloth',)\n",
            "('blue', 'snake') ('blue', 'snake')\n",
            "('sloth',) ('sloth',)\n",
            "('sloth',) ('sloth',)\n",
            "('blue', 'monkey') ('blue', 'monkey')\n",
            "('lion', 'pink') ('lion', 'pink')\n",
            "('blue', 'crane') ('blue', 'crane')\n",
            "('green', 'lion') ('green', 'lion')\n",
            "('giraffe', 'green') ('giraffe', 'green')\n",
            "('grey', 'monkey') ('grey', 'monkey')\n",
            "('blue', 'giraffe') ('blue', 'giraffe')\n",
            "('giraffe', 'pink') ('giraffe', 'pink')\n",
            "('alarm',) ('alarm',)\n",
            "('green', 'snake') ('green', 'snake')\n",
            "('alarm',) ('alarm',)\n",
            "('grey', 'lion') ('grey', 'lion')\n",
            "('alarm',) ('alarm',)\n",
            "('blue', 'lion') ('blue', 'lion')\n",
            "('lion', 'pink') ('lion', 'pink')\n",
            "('green', 'monkey') ('green', 'monkey')\n",
            "('green', 'monkey') ('green', 'monkey')\n",
            "('crane', 'yellow') ('crane', 'yellow')\n",
            "('blue', 'crane') ('blue', 'crane')\n",
            "('sloth',) ('sloth',)\n",
            "('grey', 'lion') ('grey', 'lion')\n",
            "('grey', 'snake') ('grey', 'snake')\n",
            "('monkey', 'pink') ('monkey', 'pink')\n",
            "('monkey', 'pink') ('monkey', 'pink')\n",
            "('blue', 'snake') ('blue', 'snake')\n",
            "('monkey', 'yellow') ('monkey', 'yellow')\n",
            "('crane', 'grey') ('crane', 'grey')\n",
            "('lion', 'yellow') ('lion', 'yellow')\n",
            "('grey', 'lion') ('grey', 'lion')\n",
            "('crane', 'green') ('crane', 'green')\n",
            "('blue', 'giraffe') ('blue', 'giraffe')\n",
            "('crane', 'green') ('crane', 'green')\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(predicted_labels)):\n",
        "  print(actual_labels[i],predicted_labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nhD4Fn33A4p"
      },
      "outputs": [],
      "source": [
        "tf.saved_model.save(model, f'{dir_path}/latest_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2QSsU_H8866"
      },
      "outputs": [],
      "source": [
        "path=\"/content/drive/MyDrive/dodelido/three/IMG_1998.JPG\"\n",
        "cv2_image=cv2.imread(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "HS64Bh5b_YnR"
      },
      "outputs": [],
      "source": [
        "def read_image(image_object):\n",
        "  image_resized = tf.image.resize(image_object,[IMG_SIZE, IMG_SIZE])\n",
        "  # Normalize it from [0, 255] to [0.0, 1.0]\n",
        "  image_normalized = image_resized / 255.0\n",
        "  expanded_tensor = tf.expand_dims(image_normalized, axis=0)\n",
        "  ouptut=model.predict(expanded_tensor)\n",
        "  result_list = list(ouptut)\n",
        "  binary_array = np.where(np.array(result_list) > threshold, 1, 0)\n",
        "  result=mlb.inverse_transform(binary_array)\n",
        "  print(result)\n",
        "\n",
        "\n",
        "def filter_overlapping_circles(circles, min_dist_between_circles):\n",
        "  filtered_circles = []\n",
        "\n",
        "  for circle in circles[0]:\n",
        "      x, y, r = circle\n",
        "      overlap = False\n",
        "      for fc in filtered_circles:\n",
        "          fx, fy, fr = fc\n",
        "          distance = np.sqrt((x - fx) ** 2 + (y - fy) ** 2)\n",
        "          if distance < min_dist_between_circles:\n",
        "              overlap = True\n",
        "              break\n",
        "      if not overlap:\n",
        "          filtered_circles.append(circle)\n",
        "\n",
        "  return (filtered_circles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "ECww0kHk-25T"
      },
      "outputs": [],
      "source": [
        "path=\"/content/drive/MyDrive/dodelido/three/IMG_2017.JPG\"\n",
        "target_width = 1024\n",
        "target_height = 1024\n",
        "image=cv2.imread(path)\n",
        "# image = cv2.resize(cv2_image, (target_width, target_height))\n",
        "\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "# Use Hough Circle Transform to detect circles\n",
        "blurred = cv2.GaussianBlur(gray, (11, 11), 0)\n",
        "circles = cv2.HoughCircles(\n",
        "    blurred,\n",
        "    cv2.HOUGH_GRADIENT,\n",
        "    dp=1,\n",
        "    minDist=500,         # Adjust based on expected circle density\n",
        "    param1=100,         # Higher threshold for Canny edge detector\n",
        "    param2=30,          # Lower accumulator threshold for circle detection\n",
        "    minRadius=100,       # Adjust based on the smallest expected circle size\n",
        "    maxRadius=450       # Adjust based on the largest expected circle size\n",
        ")\n",
        "\n",
        "images=[]\n",
        "buffer=20\n",
        "if circles is not None:\n",
        "    # Convert the (x, y) coordinates and radius of the circles to integers\n",
        "    circles = circles.astype(int)\n",
        "    min_dist_between_circles = 500  # Adjust this value as needed\n",
        "    filtered_circles = filter_overlapping_circles(circles, min_dist_between_circles)\n",
        "\n",
        "    # Loop over all detected circles\n",
        "    for circle in filtered_circles:\n",
        "        # Extract the coordinates and radius of the circle\n",
        "        x, y, r = circle\n",
        "\n",
        "        # Draw the bounding box around the circle\n",
        "        x1 = max(0, x - r-buffer)\n",
        "        y1 = max(0, y - r-buffer)\n",
        "        x2 = min(image.shape[1], x + r+buffer)\n",
        "        y2 = min(image.shape[0], y + r+buffer)\n",
        "\n",
        "        # cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        # Draw the bounding box on the original image\n",
        "        new_image= image[y1:y2, x1:x2]\n",
        "        images.append(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in images:\n",
        "  read_image(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56RH4IJrDxB-",
        "outputId": "514a8155-ca2b-4724-c60c-dd57c4a9abe3"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "[('giraffe', 'pink')]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "[('grey', 'snake')]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "[('alarm',)]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
